# -*- coding: utf-8 -*-
"""phase 1: image preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KOzQvnGTILUD9pFmWH87C96dZQCBWt3F

# import library
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/gdrive/My Drive/flick_dataset_preprocessing"

import pandas as pd
import numpy as np
import cv2
import os
import json
import glob
import shutil
import os

"""# Đọc dữ liệu từ  flickr_logos_27_dataset_training_set_annotation.txt"""

# đọc dữ liệu từ flie text 
dataset = pd.read_csv("flickr_logos_27_dataset_training_set_annotation.txt",header= None, sep=" ")
# đổi tên các cột sang tên tương ứng
flick = dataset.rename(columns={0:"file_name",1:"categories_names",2: "Training subset",3:"xmin",4:"ymin",5:"xmax",6:"ymax"})
# bỏ cột 7 do là cột trống 
flick = flick.drop([7], axis=1)

flick

"""Giải thích ý nghĩa các cột:


*   file_name: tên hình
*   categories_names: tên nhãn của logo
*   Training subset: Training subset 
*   xmin 	ymin 	xmax 	ymax: Coordinates của 2 điểm để tạo bounding box
"""

# sort lại hình ảnh
flick = flick.sort_values(by=['file_name']).reset_index(drop=True)
#thêm vào 2 cột width và height của hình ảnh
flick["width"] = 0
flick["height"] = 0

path = "flickr_logos_27_dataset_images"
# thêm vào width và height cho dataset
for i in range(len(flick)):
  im = cv2.imread(os.path.join(path,flick['file_name'][i])) 
  h, w, c = im.shape
  flick["width"][i] = w
  flick["height"][i] = h

# tạo một cột mới chứa width và height của hình ảnh
flick['image_shape'] = list(zip(flick.width, flick.height))

# dataset sau khi trải qua xử lý
flick

#save flick
flick.to_csv(r'/content/gdrive/My Drive/flick_dataset_preprocessing/flick.txt', index=None, sep='\t', mode='a')

"""# phân tích dataset sau preprocressing"""

print("số lượng logo: ", len(flick) )
print("số lượng hình: ", flick["file_name"].nunique())
print("sô 1ượng brands: ",flick["categories_names"].nunique())

print("số lượng hình thuộc từng brand")
counts = flick["file_name"].value_counts()
flick["categories_names"].value_counts()

flick["image_shape"].value_counts()

"""# tạo bộ dataset flick dựa trên thông tin từ flick dataframe"""

# vì bộ flickr_logos_27_dataset_images chứa những hình không được đánh dấu, ta cần tạo một bộ dataset mới chỉ có hình ảnh nằm trong flick
# đọc tất cả các tên đặt biệt từ flick
# chuyển tất cả các file ảnh từ dataset flickr_logos_27_dataset_images về một folder mới 

src_dir = "/content/gdrive/My Drive/flick_dataset_preprocessing/flickr_logos_27_dataset_images"
dst_dir = "/content/gdrive/My Drive/mmdetection/flick/training/image_2"
uquine_name = flick["file_name"].unique()
for  i in range(len(uquine_name)):
    name = uquine_name[i]
    jpgfile = os.path.join(src_dir,name)
    shutil.copy(jpgfile, dst_dir)

"""# chuyển dữ liệu từ flickr_logos_27_dataset_training_set_annotation.txt về dạng custom format cho mmdetection"""

#  đọc dữ liệu từ flick và chuyển về dạng format thích hợp cho mmdetection

dst_dir2 = "/content/gdrive/My Drive/mmdetection/flick/training/label_2"
for  i in range(len(uquine_name)):
 
  name = uquine_name[i]
  df3 = flick[flick.file_name == name].reset_index(drop = True)
  text_name = name[:-4]+ ".txt"
  text_name_dir = os.path.join(dst_dir2,text_name)
  with open(text_name_dir, "w") as text_file:
      for  j in range(len(df3)):
        label = "Car"
        x1 = str(df3["xmin"][j])
        y1 = str(df3["ymin"][j])
        x2 = str(df3["xmax"][j])
        y2 = str(df3["ymax"][j])
        strings = label + " " + x1 + " " + y1 + " " + x2 + " " + y2
        text_file.write(strings)
        text_file.write("\n")

"""# convert sang middle format cho mmdetection"""

# đọc dữ liệu từ flick dataframe và chuyển về dạng middle format để sử sụng cho mmdetection

df2 = flick
i=0
uquine_name = flick["file_name"].unique()
data_infos = []

for i in range(len(uquine_name)): # loop qua 809 hình trong training
  #tạo list rỗng đễ chứa tọa độ của bounding box và label
  bboxes = []
  labels = []
  
  bboxes_ignore = []
  labels_ignore = []
  #lấy ra tên từng hình
  name = uquine_name[i]
  
  #dùng tên hình tạo dataframe mới chỉ chứa hình đó
  df3 = df2[df2.file_name == name].reset_index(drop = True)

  # lấy ra shape của hình
  w = df3["width"][0]
  h = df3["height"][0]

  #loop qua tất cả các boundind box và label của boundind box trong hình
  #bỏ vào trong 2 list rỗng bboxes và labels
  for j in range(len(df3)):
    x1 = df3["xmin"][j]
    y1 = df3["ymin"][j]
    x2 = df3["xmax"][j]
    y2 = df3["ymax"][j]
    bboxes.append([x1,y1,x2,y2])
    labels.append(1)

  # chuyển về np.array theo yêu cầu của format
  bboxes=np.array(bboxes).astype(np.float32)
  labels=np.array(labels).astype(np.int64)
  
  bboxes_ignore=np.array(bboxes_ignore).astype(np.float32)
  labels_ignore=np.array(labels_ignore).astype(np.int64)
  #tạo một list mới theo format 
  data = [
    {
        'filename':name,
        'width': w,
        'height': h,
        'ann': {
            'bboxes': bboxes,
            'labels': labels,
            'bboxes_ignore': bboxes_ignore,
            'labels_ignore': labels_ignore
        }
    }

  ]

  #thêm lost đó vào list chung
  data_infos.append(data)

"""# extract to json format"""

# tạo class MyEncoder để tránh lỗi

class MyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return super(MyEncoder, self).default(obj)

# extract ra json format và kiểm tra
jstr = json.dumps(data_infos, indent=4,cls=MyEncoder)
print(jstr)

# save về một file mới để sử dụng mmdetection

with open('data_middle_format_2.json', 'w') as outfile:
    json.dump(data_infos, outfile,cls=MyEncoder)