{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"phase 2: image preprocessing.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"gEP3fMi87OKD","colab_type":"text"},"source":["# import library"]},{"cell_type":"code","metadata":{"id":"jch4Geo_6gOw","colab_type":"code","colab":{},"outputId":"adaed63e-7a1d-4a58-9c01-8153c7fa3a5b"},"source":["import matplotlib.pyplot\n","import numpy as np\n","import os\n","from PIL import Image\n","from collections import defaultdict\n","from itertools import product\n","from sklearn.model_selection import train_test_split\n","import shutil\n","import re\n","import glob\n","from scipy import ndimage\n","import pickle\n","from six.moves import cPickle as pickle\n","from six.moves import range\n","#from __future__ import division, print_function, absolute_import\n","import tflearn\n","from tflearn.data_utils import shuffle\n","from tflearn.layers.core import input_data, dropout, fully_connected\n","from tflearn.layers.conv import conv_2d, max_pool_2d\n","from tflearn.layers.estimator import regression\n","from tflearn.data_preprocessing import ImagePreprocessing\n","from tflearn.data_augmentation import ImageAugmentation\n","import tensorflow as tf"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","C:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n","WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n","\n","WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From C:\\anaconda3\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KkwUKVz16gO2","colab_type":"code","colab":{},"outputId":"58b44eb4-61d1-4ec1-de3d-b8808681fc4c"},"source":["%cd \"D:\\\\Ananconda\\\\login detect\\\\dataset\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["D:\\Ananconda\\login detect\\dataset\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mvLKmAGo7XDR","colab_type":"text"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"id":"GqHDKG7X6gO8","colab_type":"code","colab":{}},"source":["# khai báo width height, rotation, shift, scale parameter\n","\n","width = 32\n","height = 32\n","\n","posshiftshift_min = -5\n","posshiftshift_max = 5\n","scales = [0.9, 1.1]\n","rot_min = -15\n","rot_max = 15\n","\n","dir = 'dataset'\n","imgdir = os.path.join(dir, 'main_dataset')\n","pp_dir = os.path.join(\n","    dir, 'dataset8')\n","annot = 'result.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8mk1YZ0k6gPB","colab_type":"code","colab":{},"outputId":"7013faac-7b8e-4b72-c310-3b7622bc3061"},"source":["annot_train = np.loadtxt(os.path.join(dir, annot), dtype='a')\n","print('train_annotation: %d, %d ' % (annot_train.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_annotation: 4536, 7 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eUKEecpA7a9t","colab_type":"text"},"source":["# Crop và augmente data"]},{"cell_type":"markdown","metadata":{"id":"7fZsDy0JGxyq","colab_type":"text"},"source":["## augmente data"]},{"cell_type":"code","metadata":{"id":"DiSCLe_o6gPH","colab_type":"code","colab":{}},"source":["\n","# lấy bounding box từ text file\n","\n","def parse_annot(annot):\n","    fn = annot[0].decode('utf-8')\n","    class_name = annot[1].decode('utf-8')\n","    train_subset_class = annot[2].decode('utf-8')\n","    return fn, class_name, train_subset_class\n","\n","def get_rect(annot):             \n","    rect = defaultdict(int)\n","    x1, y1, x2, y2 = rect_coord(annot[3:])\n","    cx, cy, wid, hgt = center_wid_hgt(x1, y1, x2, y2)\n","    rect['x1'] = x1\n","    rect['y1'] = y1\n","    rect['x2'] = x2\n","    rect['y2'] = y2\n","    rect['cx'] = cx\n","    rect['cy'] = cy\n","    rect['wid'] = wid\n","    rect['hgt'] = hgt\n","    return rect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H9hl5kLk6gPL","colab_type":"code","colab":{}},"source":["# shift vị trí bounding box trong hình\n","\n","def posshift(annot, im):   \n","    posshift_ims = []\n","    posshift_suffixes = []\n","\n","    rect = get_rect(annot)\n","    for sx, sy in product(                        \n","            range(posshiftshift_min, posshiftshift_max),\n","            range(posshiftshift_min, posshiftshift_max)):\n","        cx = rect['cx'] + sx\n","        cy = rect['cy'] + sy\n","        cropped_im = im.crop((cx - rect['wid'] // 2, cy - rect['hgt'] // 2,\n","                              cx + rect['wid'] // 2, cy + rect['hgt'] // 2))\n","        resized_im = cropped_im.resize((width, height))\n","        posshift_ims.append(resized_im)\n","        posshift_suffixes.append('p' + str(sx) + str(sy))\n","        cropped_im.close()\n","\n","    return posshift_ims, posshift_suffixes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8074VuJh6gPP","colab_type":"code","colab":{}},"source":["# sclae bounding box theo parameter\n","\n","def scale(annot, im):   \n","    scale_ims = []\n","    scale_suffixes = []\n","\n","    rect = get_rect(annot)\n","    for s in scales:\n","        w = int(rect['wid'] * s)\n","        h = int(rect['hgt'] * s)\n","        cropped_im = im.crop((rect['cx'] - w // 2, rect['cy'] - h // 2,\n","                              rect['cx'] + w // 2, rect['cy'] + h // 2))\n","        resized_im = cropped_im.resize((width, height))\n","        scale_ims.append(resized_im)\n","        scale_suffixes.append('s' + str(s))\n","        cropped_im.close()\n","\n","    return scale_ims, scale_suffixes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ABqWEaez6gPU","colab_type":"code","colab":{}},"source":["# rotate bounding box theo parameter\n","\n","\n","def rotate(annot, im):   \n","    rotate_ims = []\n","    rotate_suffixes = []\n","\n","    rect = get_rect(annot)\n","    for r in range(rot_min, rot_max):\n","        rotated_im = im.rotate(r)\n","        cropped_im = rotated_im.crop(\n","            (rect['cx'] - rect['wid'] // 2, rect['cy'] - rect['hgt'] // 2,\n","             rect['cx'] + rect['wid'] // 2, rect['cy'] + rect['hgt'] // 2))\n","        resized_im = cropped_im.resize((width, height))\n","        rotate_ims.append(resized_im)\n","        rotate_suffixes.append('r' + str(r))\n","        rotated_im.close()\n","        cropped_im.close()\n","\n","    return rotate_ims, rotate_suffixes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zEuHaO7G3sw","colab_type":"text"},"source":["## crop hình"]},{"cell_type":"code","metadata":{"id":"8RrNE3Co6gPa","colab_type":"code","colab":{}},"source":["#Cropping the logo\n","\n","def crop(annot, im):                        \n","    x1, y1, x2, y2 = rect_coord(annot[3:])\n","    cropped_im = im.crop((x1, y1, x2, y2))\n","    cropped_im = cropped_im.resize((width, height))\n","    cropped_suffix = 'p00'\n","    return [cropped_im], [cropped_suffix]\n","\n","\n","def rect_coord(annot_part):\n","    return list(map(int, annot_part))   \n","\n","\n","def center_wid_hgt(x1, y1, x2, y2):\n","    cx = x1 + (x2 - x1) // 2\n","    cy = y1 + (y2 - y1) // 2\n","    wid = (x2 - x1)\n","    hgt = (y2 - y1)\n","    return cx, cy, wid, hgt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mc7J7LWS6gPf","colab_type":"code","colab":{}},"source":["# kiểm tra điều kiện bỏ logo, save hình và đóng file\n","\n","\n","def is_skip(annot_part):\n","    x1, y1, x2, y2 = rect_coord(annot_part)\n","    _, _, wid, hgt = center_wid_hgt(x1, y1, x2, y2)\n","    if wid <= 0 or hgt <= 0:\n","        return True\n","    else:\n","        return False\n","\n","def save_im(annot, cnt, *args):         \n","    fn, class_name, train_subset_class = parse_annot(annot)\n","    dst_dir = os.path.join(pp_dir, class_name)\n","    if not os.path.exists(dst_dir):\n","        os.makedirs(dst_dir)\n","    for i, arg in enumerate(args):\n","        for im, suffix in zip(arg[0], arg[1]):\n","            save_fn = '_'.join([\n","                fn.split('.')[0], class_name, train_subset_class, str(cnt),\n","                suffix\n","            ]) + os.path.splitext(fn)[1]\n","            im.save(os.path.join(dst_dir, save_fn))\n","\n","\n","def close_im(*args):\n","    for ims in args:\n","        for im in ims:\n","            im.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaz355bG6gPj","colab_type":"code","colab":{}},"source":["# parent function để gọi tất cà các sub functions\n","\n","def crop_and_aug(annot_train):    \n","    cnt_per_file = defaultdict(int)\n","    for annot in annot_train:\n","        # for generating a file name\n","        fn, _, _ = parse_annot(annot)\n","        cnt_per_file[fn] += 1\n","\n","        # skip if width or height equal zero\n","        if is_skip(annot[3:]):\n","            print('Skip: ', fn)\n","            continue\n","\n","        # open an image\n","        im = Image.open(os.path.join(imgdir, fn))\n","\n","        # normal cropping\n","        cropped_ims, cropped_suffixes = crop(annot, im)\n","\n","        # augment by shifting a center\n","        shifted_ims, shifted_suffixes = posshift(annot, im)\n","\n","        # augment by scaling\n","        scaled_ims, scaled_suffixes = scale(annot, im)\n","\n","        # augment by rotation\n","        rotated_ims, rotated_suffixes = rotate(annot, im)\n","\n","        # save images\n","        save_im(annot, cnt_per_file[fn], [cropped_ims, cropped_suffixes],\n","                [shifted_ims, shifted_suffixes], [scaled_ims, scaled_suffixes],\n","                [rotated_ims, rotated_suffixes])\n","\n","        # close image file\n","        close_im([im], cropped_ims, shifted_ims, scaled_ims, rotated_ims)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b2kVm1CLG6bl","colab_type":"text"},"source":["## tạo dataset"]},{"cell_type":"code","metadata":{"id":"guXAqksi6gPp","colab_type":"code","colab":{}},"source":["# gọi tất cà các function và tạo dataset mới\n","\n","def crop_and_aug_with_none(annot_train, with_none=False):\n","    # root directory to save processed images\n","    if not os.path.exists(pp_dir):\n","        os.makedirs(pp_dir)\n","\n","    # crop images and apply augmentation\n","    crop_and_aug(annot_train)\n","\n","    # print results\n","    org_imgs = [img for img in os.listdir(imgdir)]\n","    crop_and_aug_imgs = [\n","        fname\n","        for root, dirs, files in os.walk(pp_dir)\n","        for fname in glob.glob(os.path.join(root, '*.jpg'))  # look for the file with .jpg extension.\n","    ]\n","    print('original: %d' % (len(org_imgs)))\n","    print('cropped: %d' % (len(crop_and_aug_imgs)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7rOZOB64GuBe","colab_type":"text"},"source":["# splitting data"]},{"cell_type":"code","metadata":{"id":"a4khRaGw6gPt","colab_type":"code","colab":{}},"source":["# tạo train và test set\n","def do_train_test_split():                                   \n","    class_names = [cls for cls in os.listdir(pp_dir)]\n","   # create directories under a particular class name.\n","    for class_name in class_names:                           \n","        if os.path.exists(                                  \n","                os.path.join(pp_dir, class_name, 'train')):\n","            continue\n","        if os.path.exists(\n","                os.path.join(pp_dir, class_name, 'test')):\n","            continue\n","\n","        imgs = [\n","            img\n","            for img in os.listdir(\n","                os.path.join(pp_dir, class_name))\n","        ]\n","        # train=0.75, test=0.25\n","        train_imgs, test_imgs = train_test_split(imgs)\n","        # move images to train or test directory\n","        # create directories\n","        os.makedirs(os.path.join(pp_dir, class_name, 'train'))         \n","        os.makedirs(os.path.join(pp_dir, class_name, 'test'))\n","        for img in train_imgs:\n","            dst = os.path.join(pp_dir, class_name, 'train')\n","            src = os.path.join(pp_dir, class_name, img)\n","            # moving image into that directory\n","            shutil.move(src, dst)                                      \n","        for img in test_imgs:\n","            dst = os.path.join(pp_dir, class_name, 'test')\n","            src = os.path.join(pp_dir, class_name, img)\n","            shutil.move(src, dst)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gY2J-ozwHB7L","colab_type":"text"},"source":["# gọi function"]},{"cell_type":"code","metadata":{"id":"y0EwVy8L6gPx","colab_type":"code","colab":{},"outputId":"504ae83b-8a6f-4bda-e166-75e1117e8472"},"source":["crop_and_aug_with_none(annot_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Skip:  2662264721.jpg\n","Skip:  2662264721.jpg\n","Skip:  2662264721.jpg\n","Skip:  2662264721.jpg\n","Skip:  2662264721.jpg\n","original: 1079\n","cropped: 598092\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mfV9eFIX6gP0","colab_type":"code","colab":{}},"source":["do_train_test_split()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g45vjwWvHG5q","colab_type":"text"},"source":["# Tạo Pickle File chứa dataset"]},{"cell_type":"markdown","metadata":{"id":"jJxKrD1KHvSY","colab_type":"text"},"source":["## tạo thông số cho pickle file"]},{"cell_type":"code","metadata":{"id":"KYo1Iwtr6gP_","colab_type":"code","colab":{}},"source":["#Parameters của hình\n","width = 32     \n","height = 32    \n","channel = 3         \n","pix_val = 255.0\n","\n","dir = 'dataset'\n","# Directory where processed images are stored\n","pp_dir = os.path.join(dir, 'dataset8') \n","# tên pickle file\n","pickle_file = 'logo_dataset.pickle'    \n","# sớ hình sử dụng cho training và validate\n","train_size = 70000  \n","val_size = 5000\n","# sớ hình sử dụng cho test\n","test_size = 7000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3IK2BtVF6gQC","colab_type":"code","colab":{}},"source":["# tạo một array chứa height, width và channel các hình trong dataset\n","\n","def array(nb_rows, image_width, image_height, image_ch=1):     \n","    if nb_rows:\n","        dataset = np.ndarray(                               #  stores its height, width and channel into an array\n","            (nb_rows, image_height, image_width, image_ch), dtype=np.float32)\n","        labels = np.ndarray(nb_rows, dtype=np.int32)        #  stores its labels\n","    else:\n","        dataset, labels = None, None\n","    return dataset, labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HPRWDd7IBoh","colab_type":"text"},"source":["## các function cho việc tạo pickle"]},{"cell_type":"code","metadata":{"id":"CNE6EsqQ6gQF","colab_type":"code","colab":{}},"source":["# dụng nhập pickle files của 10 classes vào chung pickle file.\n","\n","def combine(pickle_files, train_size, val_size=0):     \n","    num_classes = len(pickle_files)\n","    valid_dataset, valid_labels = array(val_size, width,\n","                                              height, channel)\n","    train_dataset, train_labels = array(train_size, width,\n","                                              height, channel)\n","    vsize_per_class = val_size // num_classes\n","    tsize_per_class = train_size // num_classes\n","\n","    start_v, start_t = 0, 0\n","    end_v, end_t = vsize_per_class, tsize_per_class\n","    end_l = vsize_per_class + tsize_per_class\n","    for label, pickle_file in enumerate(pickle_files):\n","        try:\n","            with open(pickle_file, 'rb') as f:\n","                logo_set = pickle.load(f)\n","                np.random.shuffle(logo_set)\n","                if valid_dataset is not None:\n","                    valid_logo = logo_set[:vsize_per_class, :, :, :]\n","                    valid_dataset[start_v:end_v, :, :, :] = valid_logo\n","                    valid_labels[start_v:end_v] = label\n","                    start_v += vsize_per_class\n","                    end_v += vsize_per_class\n","                train_logo = logo_set[vsize_per_class:end_l, :, :, :]\n","                train_dataset[start_t:end_t, :, :, :] = train_logo\n","                train_labels[start_t:end_t] = label\n","                start_t += tsize_per_class\n","                end_t += tsize_per_class\n","        except Exception as e:\n","            print('Unable to process data from', pickle_file, ':', e)\n","            raise\n","    return valid_dataset, valid_labels, train_dataset, train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nWJ0rteZ6gQL","colab_type":"code","colab":{}},"source":["# tạo pickle files cho một class\n","\n","def makepickle(train_dataset, train_labels, valid_dataset, valid_labels,   \n","                test_dataset, test_labels):\n","    try:\n","        f = open(pickle_file, 'wb')\n","        save = {\n","            'train_dataset': train_dataset,\n","            'train_labels': train_labels,\n","            'valid_dataset': valid_dataset,\n","            'valid_labels': valid_labels,\n","            'test_dataset': test_dataset,\n","            'test_labels': test_labels,\n","        }\n","        pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)      # Saving data of the images into a pickle file\n","        f.close()\n","    except Exception as e:\n","        print('Unable to save data to', pickle_file, ':', e)\n","        raise"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aoJhXDHe6gQP","colab_type":"code","colab":{}},"source":["# load hình logo từ thông số\n","\n","def load_logo(data_dir):    \n","    image_files = os.listdir(data_dir)      \n","    dataset = np.ndarray(\n","        shape=(len(image_files), height, width, channel),\n","        dtype=np.float32)\n","    print(data_dir)\n","    num_images = 0\n","    for image in image_files:\n","        image_file = os.path.join(data_dir, image)\n","        try:\n","            image_data = (matplotlib.pyplot.imread(image_file).astype(float) -        \n","                          pix_val / 2) / pix_val\n","            if image_data.shape != (height, width, channel):\n","                raise Exception('Unexpected image shape: %s' %\n","                                str(image_data.shape))\n","            dataset[num_images, :, :] = image_data\n","            num_images = num_images + 1\n","        except IOError as e:\n","            print('Could not read:', image_file, ':', e,\n","                  '-it\\'s ok, skipping.')\n","\n","    dataset = dataset[0:num_images, :, :]                           \n","    print('Full dataset tensor:', dataset.shape)       # Tell processed number of images for a particular class \n","    print('Mean:', np.mean(dataset))                   # Calculate mean over that entire class\n","    print('Standard deviation:', np.std(dataset))      # Calculate standard deviation over that entire class\n","    return dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZuIKJSBe6gQS","colab_type":"code","colab":{}},"source":["# tạo  parent function Pickle file từ các sub functions\n","def pickling(data_dirs, force=False):     \n","    dataset_names = []\n","    for dir in data_dirs:\n","        set_filename = dir + '.pickle'\n","        dataset_names.append(set_filename)\n","\n","         \n","        if os.path.exists(set_filename) and force:    \n","    \n","            print('%s already present - Skipping pickling. ' % set_filename)\n","        else:\n","            print('Pickling %s.' % set_filename)\n","            dataset = load_logo(dir)\n","            try:\n","                with open(set_filename, 'wb') as f:\n","                    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n","            except Exception as e:\n","                print('Unable to save data to', set_filename, ':', e)\n","    return dataset_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5aVXAuOy6gQW","colab_type":"code","colab":{}},"source":["def randomize(dataset, labels):\n","    permutation = np.random.permutation(labels.shape[0])\n","    shuffled_dataset = dataset[permutation, :, :]\n","    shuffled_labels = labels[permutation]\n","    return shuffled_dataset, shuffled_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FViC6V6rLLDj","colab_type":"text"},"source":["# tạo pickle file"]},{"cell_type":"code","metadata":{"id":"1EbmUcMv6gQc","colab_type":"code","colab":{}},"source":["CLASS_NAME = [\n","   'Apple', 'BMW','Heineken','HP','Intel','Mini','Starbucks','Vodafone', 'unknown', 'Ferrari'\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-rCc57FdWPq","colab_type":"code","colab":{},"outputId":"4db5483c-c904-4a02-cb0d-ffe0fb460c77"},"source":["dirs = [\n","        os.path.join(pp_dir, class_name, 'train')      # Look into all the train folder of the class\n","        for class_name in CLASS_NAME\n","    ]\n","test_dirs = [\n","        os.path.join(pp_dir, class_name, 'test')        # Look into all the test folder of the class\n","        for class_name in CLASS_NAME\n","    ]\n","\n","train_datasets = pickling(dirs)\n","test_datasets = pickling(test_dirs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pickling flickrData\\processedF2\\Apple\\train.pickle.\n","flickrData\\processedF2\\Apple\\train\n","Full dataset tensor: (25443, 32, 32, 3)\n","Mean: 0.11680751\n","Standard deviation: 0.29468784\n","Pickling flickrData\\processedF2\\BMW\\train.pickle.\n","flickrData\\processedF2\\BMW\\train\n","Full dataset tensor: (11781, 32, 32, 3)\n","Mean: -0.07805122\n","Standard deviation: 0.30858785\n","Pickling flickrData\\processedF2\\Heineken\\train.pickle.\n","flickrData\\processedF2\\Heineken\\train\n","Full dataset tensor: (15939, 32, 32, 3)\n","Mean: -0.08372974\n","Standard deviation: 0.26778436\n","Pickling flickrData\\processedF2\\HP\\train.pickle.\n","flickrData\\processedF2\\HP\\train\n","Full dataset tensor: (10989, 32, 32, 3)\n","Mean: -0.11454076\n","Standard deviation: 0.33904904\n","Pickling flickrData\\processedF2\\Intel\\train.pickle.\n","flickrData\\processedF2\\Intel\\train\n","Full dataset tensor: (12177, 32, 32, 3)\n","Mean: 0.1226464\n","Standard deviation: 0.32122466\n","Pickling flickrData\\processedF2\\Mini\\train.pickle.\n","flickrData\\processedF2\\Mini\\train\n","Full dataset tensor: (10395, 32, 32, 3)\n","Mean: -0.07943848\n","Standard deviation: 0.29290244\n","Pickling flickrData\\processedF2\\Starbucks\\train.pickle.\n","flickrData\\processedF2\\Starbucks\\train\n","Full dataset tensor: (18612, 32, 32, 3)\n","Mean: -0.10516442\n","Standard deviation: 0.24233244\n","Pickling flickrData\\processedF2\\Vodafone\\train.pickle.\n","flickrData\\processedF2\\Vodafone\\train\n","Full dataset tensor: (26037, 32, 32, 3)\n","Mean: 0.053684127\n","Standard deviation: 0.32983187\n","Pickling flickrData\\processedF2\\unknown\\train.pickle.\n","flickrData\\processedF2\\unknown\\train\n","Full dataset tensor: (20790, 32, 32, 3)\n","Mean: 0.08976112\n","Standard deviation: 0.34628597\n","Pickling flickrData\\processedF2\\Ferrari\\train.pickle.\n","flickrData\\processedF2\\Ferrari\\train\n","Full dataset tensor: (10395, 32, 32, 3)\n","Mean: -0.10250373\n","Standard deviation: 0.31474072\n","Pickling flickrData\\processedF2\\Apple\\test.pickle.\n","flickrData\\processedF2\\Apple\\test\n","Full dataset tensor: (8481, 32, 32, 3)\n","Mean: 0.115431786\n","Standard deviation: 0.29469076\n","Pickling flickrData\\processedF2\\BMW\\test.pickle.\n","flickrData\\processedF2\\BMW\\test\n","Full dataset tensor: (3927, 32, 32, 3)\n","Mean: -0.0783203\n","Standard deviation: 0.30838534\n","Pickling flickrData\\processedF2\\Heineken\\test.pickle.\n","flickrData\\processedF2\\Heineken\\test\n","Full dataset tensor: (5313, 32, 32, 3)\n","Mean: -0.0855073\n","Standard deviation: 0.26715967\n","Pickling flickrData\\processedF2\\HP\\test.pickle.\n","flickrData\\processedF2\\HP\\test\n","Full dataset tensor: (3663, 32, 32, 3)\n","Mean: -0.11300446\n","Standard deviation: 0.3386933\n","Pickling flickrData\\processedF2\\Intel\\test.pickle.\n","flickrData\\processedF2\\Intel\\test\n","Full dataset tensor: (4059, 32, 32, 3)\n","Mean: 0.11710768\n","Standard deviation: 0.32303488\n","Pickling flickrData\\processedF2\\Mini\\test.pickle.\n","flickrData\\processedF2\\Mini\\test\n","Full dataset tensor: (3465, 32, 32, 3)\n","Mean: -0.078316286\n","Standard deviation: 0.29152557\n","Pickling flickrData\\processedF2\\Starbucks\\test.pickle.\n","flickrData\\processedF2\\Starbucks\\test\n","Full dataset tensor: (6204, 32, 32, 3)\n","Mean: -0.10340854\n","Standard deviation: 0.2425315\n","Pickling flickrData\\processedF2\\Vodafone\\test.pickle.\n","flickrData\\processedF2\\Vodafone\\test\n","Full dataset tensor: (8679, 32, 32, 3)\n","Mean: 0.054444574\n","Standard deviation: 0.32966584\n","Pickling flickrData\\processedF2\\unknown\\test.pickle.\n","flickrData\\processedF2\\unknown\\test\n","Full dataset tensor: (6930, 32, 32, 3)\n","Mean: 0.08457614\n","Standard deviation: 0.3472837\n","Pickling flickrData\\processedF2\\Ferrari\\test.pickle.\n","flickrData\\processedF2\\Ferrari\\test\n","Full dataset tensor: (3465, 32, 32, 3)\n","Mean: -0.098723166\n","Standard deviation: 0.3162948\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5UCq0eBM6gQk","colab_type":"code","colab":{}},"source":["valid_dataset, valid_labels, train_dataset, train_labels = combine(train_datasets, train_size, val_size)# function called for merging"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53oBl6Yg6gQn","colab_type":"code","colab":{}},"source":["a,b,test_dataset, test_labels= combine(test_datasets, test_size, val_size=0)\n","\n","train_dataset, train_labels = randomize(train_dataset, train_labels)   # function called for randomizing\n","valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)  \n","test_dataset, test_labels = randomize(test_dataset, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuiwOJMU6gQs","colab_type":"code","colab":{},"outputId":"91393cc3-3d9f-4d5a-ed02-6968e4741997"},"source":["makepickle(train_dataset, train_labels, valid_dataset, valid_labels,test_dataset, test_labels)# function called for making a pickle file.\n","statinfo = os.stat(pickle_file)                         # Shows size of the file \n","print('Compressed pickle size:', statinfo.st_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Compressed pickle size: 1007944511\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZvuP1WApLGlg","colab_type":"text"},"source":["# test the dataset"]},{"cell_type":"code","metadata":{"id":"ECqESFwp6gQv","colab_type":"code","colab":{},"outputId":"4c302bea-4efb-4cc1-dcc7-8762e9060558"},"source":["def read_data():\n","    with open(\"logo_dataset.pickle\", 'rb') as f:\n","        save = pickle.load(f)\n","        X = save['train_dataset']       # assign X as train dataset\n","        Y = save['train_labels']        # assign Y as train labels \n","        X_test = save['test_dataset']   # assign X_test as test dataset\n","        Y_test = save['test_labels']    #assign Y_test as test labels\n","        del save\n","    return [X, X_test], [Y, Y_test]\n","\n","def reformat(dataset, labels):   \n","    dataset = dataset.reshape((-1, 32, 32,3)).astype(np.float32)    # Reformatting shape array to give a scalar value for dataset.  \n","    labels = (np.arange(10) == labels[:, None]).astype(np.float32) \n","    return dataset, labels\n","\n","dataset, labels = read_data()\n","X,Y = reformat(dataset[0], labels[0])\n","X_test, Y_test = reformat(dataset[1], labels[1])\n","print('Training set', X.shape, Y.shape)\n","print('Test set', X_test.shape, Y_test.shape)            \n","\n","# Shuffle the data\n","X, Y = shuffle(X, Y)    # Imported from TFLearn."],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training set (70000, 32, 32, 3) (70000, 10)\n","Test set (7000, 32, 32, 3) (7000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xM9WKa9v6gQy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pNY4WgUu6gQ1","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hu2IoKbF6gRX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}